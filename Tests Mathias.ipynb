{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET SISE 2020-2021 BIG DATA MINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification dans un contexte déséquilibré - une application à la fraude bancaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Equipe projet : Mathias Da Costa Meira, Fabrice Petitfrere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTIE TESTS FABRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_train_s1 = pd.read_csv('X_train_s1.csv')\n",
    "X_train_s2 = pd.read_csv('X_train_s2.csv')\n",
    "X_train_s3 = pd.read_csv('X_train_s3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_train_s1 = pd.read_csv('y_train_s1.csv')\n",
    "y_train_s2 = pd.read_csv('y_train_s2.csv')\n",
    "y_train_s3 = pd.read_csv('y_train_s3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241588, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267570, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126740, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206410, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamètres \n",
    "params = {\"max_depth\": [3,6,9,12, None], \n",
    "            \"min_samples_leaf\": np.arange(1,9,1), \n",
    "            \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modélisation\n",
    "from time import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 241588\n",
      "Test set size : 264143\n",
      "Best estimator : {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 3}\n",
      "[[263073    215]\n",
      " [   829     26]]\n",
      "F1-score : 0.047\n",
      "ROC AUC score : 0.515\n",
      "Elapsed time : 343.9\n"
     ]
    }
   ],
   "source": [
    "# Sans resampling\n",
    "ct = DecisionTreeClassifier()\n",
    "cv = 5\n",
    "start = time()\n",
    "classTree = GridSearchCV(ct, params, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score), verbose=3)\n",
    "classTree.fit(X_train,y_train)\n",
    "# Prédiction\n",
    "y_pred_DTC = classTree.best_estimator_.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,1)\n",
    "# Métriques sur l'échantillon de validation\n",
    "cm = confusion_matrix(y_test,y_pred_DTC)\n",
    "f1 = f1_score(y_test,y_pred_DTC)\n",
    "auc = roc_auc_score(y_test,y_pred_DTC)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(classTree.best_params_))\n",
    "print(cm)\n",
    "print(\"F1-score : {0:.3f}\".format(f1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans resampling mais avec class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modélisation\n",
    "from time import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 241588\n",
      "Test set size : 264143\n",
      "Best estimator : {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4}\n",
      "[[261352   1936]\n",
      " [   790     65]]\n",
      "F1-score : 0.046\n",
      "ROC AUC score : 0.534\n",
      "Elapsed time : 341.8\n"
     ]
    }
   ],
   "source": [
    "# Sans resampling\n",
    "ct = DecisionTreeClassifier(class_weight='balanced')\n",
    "cv = 5\n",
    "start = time()\n",
    "classTree = GridSearchCV(ct, params, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score), verbose=3)\n",
    "classTree.fit(X_train,y_train)\n",
    "# Prédiction\n",
    "y_pred_DTC = classTree.best_estimator_.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,1)\n",
    "# Métriques sur l'échantillon de validation\n",
    "cm = confusion_matrix(y_test,y_pred_DTC)\n",
    "f1 = f1_score(y_test,y_pred_DTC)\n",
    "auc = roc_auc_score(y_test,y_pred_DTC)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(classTree.best_params_))\n",
    "print(cm)\n",
    "print(\"F1-score : {0:.3f}\".format(f1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 10/90 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 8860\n",
      "Test set size : 2000\n",
      "Best estimator : {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1}\n",
      "[[1962   22]\n",
      " [  13    3]]\n",
      "F1-score : 0.146\n",
      "ROC AUC score : 0.588\n",
      "Elapsed time : 6.18\n"
     ]
    }
   ],
   "source": [
    "# Avec oversampling\n",
    "ct_s1 = DecisionTreeClassifier()\n",
    "cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "classTree_s1 = GridSearchCV(ct_s1, params, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score))\n",
    "classTree_s1.fit(X_train_s1,y_train_s1)\n",
    "# Prédiction\n",
    "y_pred_DTC_s1 = classTree_s1.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation s1\n",
    "cm_s1 = confusion_matrix(y_test,y_pred_DTC_s1)\n",
    "f1_s1 = f1_score(y_test,y_pred_DTC_s1)\n",
    "auc_s1 = roc_auc_score(y_test,y_pred_DTC_s1)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train_s1.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(classTree_s1.best_params_))\n",
    "print(cm_s1)\n",
    "print(\"F1-score : {0:.3f}\".format(f1_s1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc_s1))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 5/95 + undersampling aléatoire 1:9 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 4190\n",
      "Test set size : 2000\n",
      "Best estimator : {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1}\n",
      "[[1951   33]\n",
      " [  16    0]]\n",
      "F1-score : 0.000\n",
      "ROC AUC score : 0.492\n",
      "Elapsed time : 3.246\n"
     ]
    }
   ],
   "source": [
    "# Avec oversampling + undersampling\n",
    "ct_s2 = DecisionTreeClassifier()\n",
    "cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "classTree_s2 = GridSearchCV(ct_s2, params, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score))\n",
    "classTree_s2.fit(X_train_s2,y_train_s2)\n",
    "# Prédiction\n",
    "y_pred_DTC_s2 = classTree_s2.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation s2\n",
    "cm_s2 = confusion_matrix(y_test,y_pred_DTC_s2)\n",
    "f1_s2 = f1_score(y_test,y_pred_DTC_s2)\n",
    "auc_s2 = roc_auc_score(y_test,y_pred_DTC_s2)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train_s2.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(classTree_s2.best_params_))\n",
    "print(cm_s2)\n",
    "print(\"F1-score : {0:.3f}\".format(f1_s2))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc_s2))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 30/70 + undersampling aléatoire 1:1 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 6834\n",
      "Test set size : 2000\n",
      "Best estimator : {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1}\n",
      "[[1934   50]\n",
      " [  12    4]]\n",
      "F1-score : 0.114\n",
      "ROC AUC score : 0.612\n",
      "Elapsed time : 5.874\n"
     ]
    }
   ],
   "source": [
    "# Avec oversampling + undersampling\n",
    "ct_s3 = DecisionTreeClassifier()\n",
    "cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "classTree_s3 = GridSearchCV(ct_s3, params, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score))\n",
    "classTree_s3.fit(X_train_s3,y_train_s3)\n",
    "# Prédiction\n",
    "y_pred_DTC_s3 = classTree_s3.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation s2\n",
    "cm_s3 = confusion_matrix(y_test,y_pred_DTC_s3)\n",
    "f1_s3 = f1_score(y_test,y_pred_DTC_s3)\n",
    "auc_s3 = roc_auc_score(y_test,y_pred_DTC_s3)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train_s3.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(classTree_s3.best_params_))\n",
    "print(cm_s3)\n",
    "print(\"F1-score : {0:.3f}\".format(f1_s3))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc_s3))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La deuxième stratégie de resampling (Avec oversampling SMOTE 5/95 + undersampling aléatoire 1:9) semble être la plus intéressante. Nous testerons celle là dans la suite.  \n",
    "Vraiment ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamètres\n",
    "params_rf = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 300, 400, 500]}\n",
    "\n",
    "\n",
    "params_rf_simple = {'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
    "    'n_estimators': [200, 300, 400, 500]}\n",
    "\n",
    "params_rf_xxs = {'n_estimators': [5,300], 'max_features': ['sqrt', 0.25]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 8000\n",
      "Test set size : 2000\n",
      "Best estimator : {'max_features': 0.5, 'n_estimators': 200}\n",
      "[[1984    0]\n",
      " [  16    0]]\n",
      "F1-score : 0.000\n",
      "ROC AUC score : 0.500\n",
      "Elapsed time : 368.103\n"
     ]
    }
   ],
   "source": [
    "# Sans resampling\n",
    "rfc = RandomForestClassifier()\n",
    "# cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "random_forest = GridSearchCV(rfc, params_rf_simple, cv=5, n_jobs=-1, scoring=make_scorer(f1_score), verbose=3)\n",
    "random_forest.fit(X_train,y_train)\n",
    "# Prédiction\n",
    "y_pred_bagging = random_forest.best_estimator_.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score\n",
    "cm = confusion_matrix(y_test,y_pred_bagging)\n",
    "f1 = f1_score(y_test,y_pred_bagging)\n",
    "auc = roc_auc_score(y_test,y_pred_bagging)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(random_forest.best_params_))\n",
    "print(cm)\n",
    "print(\"F1-score : {0:.3f}\".format(f1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test avec des arbres plus petits et sans gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 241588\n",
      "Test set size : 264143\n",
      "[[249503  13785]\n",
      " [   542    313]]\n",
      "F1-score : 0.042\n",
      "ROC AUC score : 0.657\n",
      "Elapsed time : 31.148\n"
     ]
    }
   ],
   "source": [
    "# Sans resampling\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=56, class_weight='balanced')\n",
    "# cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "#random_forest = GridSearchCV(rfc, params_rf_simple, cv=5, n_jobs=-1, scoring=make_scorer(f1_score), verbose=3)\n",
    "random_forest = rfc\n",
    "random_forest.fit(X_train,y_train)\n",
    "# Prédiction\n",
    "#y_pred_bagging = random_forest.best_estimator_.predict(X_test)\n",
    "y_pred_bagging = random_forest.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score\n",
    "cm = confusion_matrix(y_test,y_pred_bagging)\n",
    "f1 = f1_score(y_test,y_pred_bagging)\n",
    "auc = roc_auc_score(y_test,y_pred_bagging)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "#print(\"Best estimator : \"+str(random_forest.best_params_))\n",
    "print(cm)\n",
    "print(\"F1-score : {0:.3f}\".format(f1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 5/95 + undersampling aléatoire 1:9 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 126740\n",
      "Test set size : 264143\n",
      "Best estimator : {'max_features': 0.5, 'n_estimators': 400}\n",
      "[[262910    378]\n",
      " [   797     58]]\n",
      "F1-score : 0.090\n",
      "ROC AUC score : 0.533\n",
      "Elapsed time : 11545.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Avec oversampling + undersampling\n",
    "rf_s2 = RandomForestClassifier()\n",
    "# cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "random_forest_s2 = GridSearchCV(rf_s2, params_rf_simple, scoring=make_scorer(f1_score), cv=5, n_jobs=-1)\n",
    "random_forest_s2.fit(X_train_s2,y_train_s2)\n",
    "# Prédiction\n",
    "y_pred_bagging_s2 = random_forest_s2.best_estimator_.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation s2\n",
    "cm_s2 = confusion_matrix(y_test,y_pred_bagging_s2)\n",
    "f1_s2 = f1_score(y_test,y_pred_bagging_s2)\n",
    "auc_s2 = roc_auc_score(y_test,y_pred_bagging_s2)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train_s2.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(random_forest_s2.best_params_))\n",
    "print(cm_s2)\n",
    "print(\"F1-score : {0:.3f}\".format(f1_s2))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc_s2))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 30/70 + undersampling aléatoire 1:1 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 4190\n",
      "Test set size : 2000\n",
      "Best estimator : {'max_features': 0.25, 'n_estimators': 200}\n",
      "[[1979    5]\n",
      " [  14    2]]\n",
      "F1-score : 0.174\n",
      "ROC AUC score : 0.561\n",
      "Elapsed time : 156.729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Avec oversampling + undersampling\n",
    "rf_s2 = RandomForestClassifier()\n",
    "# cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "random_forest_s3 = GridSearchCV(rf_s2, params_rf_simple, scoring=make_scorer(f1_score), cv=5, n_jobs=-1)\n",
    "random_forest_s3.fit(X_train_s3,y_train_s3)\n",
    "# Prédiction\n",
    "y_pred_bagging_s3 = random_forest_s3.best_estimator_.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation s2\n",
    "cm_s3 = confusion_matrix(y_test,y_pred_bagging_s3)\n",
    "f1_s3 = f1_score(y_test,y_pred_bagging_s3)\n",
    "auc_s3 = roc_auc_score(y_test,y_pred_bagging_s3)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train_s3.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(random_forest_s3.best_params_))\n",
    "print(cm_s3)\n",
    "print(\"F1-score : {0:.3f}\".format(f1_s3))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc_s3))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sans resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamètres \n",
    "params_gb_simple={'n_estimators':[16,32,64,100,200], 'learning_rate':[0.25,0.1,0.05,0.025], \n",
    "            'max_depth':[1,2,4,8], 'subsample': [0.5,0.9,1], 'max_features':[0.5,0.75]} \n",
    "\n",
    "params_gb_more = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "params_gb_xxs = {'n_estimators': [200,300], 'max_depth':[8], 'learning_rate':[0.25]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 8000\n",
      "Test set size : 2000\n",
      "Best estimator : {'learning_rate': 0.25, 'max_depth': 4, 'max_features': 0.5, 'n_estimators': 32, 'subsample': 1}\n",
      "[[1977    7]\n",
      " [  16    0]]\n",
      "F1-score : 0.000\n",
      "ROC AUC score : 0.498\n",
      "Elapsed time : 301.534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Sans resampling\n",
    "gb = GradientBoostingClassifier()\n",
    "cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "boosting = GridSearchCV(gb, params_gb_simple, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score))\n",
    "boosting.fit(X_train,y_train)\n",
    "# Prédiction\n",
    "y_pred_boosting = boosting.best_estimator_.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score\n",
    "cm = confusion_matrix(y_test,y_pred_boosting)\n",
    "f1 = f1_score(y_test,y_pred_boosting)\n",
    "auc = roc_auc_score(y_test,y_pred_boosting)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(boosting.best_params_))\n",
    "print(cm)\n",
    "print(\"F1-score : {0:.3f}\".format(f1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 5/95 + undersampling aléatoire 1:9 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 4190\n",
      "Test set size : 2000\n",
      "Best estimator : {'learning_rate': 0.25, 'max_depth': 4, 'max_features': 0.5, 'n_estimators': 64, 'subsample': 0.9}\n",
      "[[1976    8]\n",
      " [  14    2]]\n",
      "F1-score : 0.154\n",
      "ROC AUC score : 0.560\n",
      "Elapsed time : 182.263\n"
     ]
    }
   ],
   "source": [
    "# Avec oversampling + undersampling\n",
    "gb_s2 = GradientBoostingClassifier()\n",
    "cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "boosting_s2 = GridSearchCV(gb_s2, params_gb_simple, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score))\n",
    "boosting_s2.fit(X_train_s2,y_train_s2)\n",
    "# Prédiction\n",
    "y_pred_boosting_s2 = boosting_s2.best_estimator_.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation s2\n",
    "cm_s2 = confusion_matrix(y_test,y_pred_boosting_s2)\n",
    "f1_s2 = f1_score(y_test,y_pred_boosting_s2)\n",
    "auc_s2 = roc_auc_score(y_test,y_pred_boosting_s2)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train_s2.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(boosting_s2.best_params_))\n",
    "print(cm_s2)\n",
    "print(\"F1-score : {0:.3f}\".format(f1_s2))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc_s2))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 30/70 + undersampling aléatoire 1:1 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 4190\n",
      "Test set size : 2000\n",
      "Best estimator : {'learning_rate': 0.25, 'max_depth': 4, 'max_features': 0.5, 'n_estimators': 64, 'subsample': 0.9}\n",
      "[[1976    8]\n",
      " [  14    2]]\n",
      "F1-score : 0.154\n",
      "ROC AUC score : 0.560\n",
      "Elapsed time : 182.263\n"
     ]
    }
   ],
   "source": [
    "# Avec oversampling + undersampling\n",
    "gb_s3 = GradientBoostingClassifier()\n",
    "cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "boosting_s3 = GridSearchCV(gb_s3, params_gb_simple, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score))\n",
    "boosting_s3.fit(X_train_s3,y_train_s3)\n",
    "# Prédiction\n",
    "y_pred_boosting_s3 = boosting_s3.best_estimator_.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "# Métriques sur l'échantillon de validation s2\n",
    "cm_s3 = confusion_matrix(y_test,y_pred_boosting_s3)\n",
    "f1_s3 = f1_score(y_test,y_pred_boosting_s3)\n",
    "auc_s3 = roc_auc_score(y_test,y_pred_boosting_s3)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train_s3.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(boosting_s3.best_params_))\n",
    "print(cm_s3)\n",
    "print(\"F1-score : {0:.3f}\".format(f1_s3))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc_s3))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train, y_train)\n",
    "X_train_s1_scaled = scaler.fit_transform(X_train_s1, y_train)\n",
    "X_train_s2_scaled = scaler.fit_transform(X_train_s2, y_train)\n",
    "X_train_s3_scaled = scaler.fit_transform(X_train_s3, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 30/70 + undersampling aléatoire 1:1 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamètres \n",
    "params_lr_small={'class_weight':[None,'balanced']} \n",
    "params_lr_large = {'class_weight':[None,'balanced'], 'penalty':['l2', None], 'C':[0.001,0.01,0.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   31.0s finished\n",
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 241588\n",
      "Test set size : 264143\n",
      "Best estimator : {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "[[179656  83632]\n",
      " [   320    535]]\n",
      "F1-score : 0.013\n",
      "ROC AUC score : 0.654\n",
      "Elapsed time : 32.118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, make_scorer\n",
    "from time import time\n",
    "\n",
    "# Sans resampling\n",
    "model = LogisticRegression()\n",
    "cv = 5\n",
    "start = time()\n",
    "model = GridSearchCV(model, params_lr_large, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score), verbose=3)\n",
    "model.fit(X_train_scaled,y_train)\n",
    "\n",
    "# Prédiction\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "#y_pred = model.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "#lr_best_params = model.best_params_\n",
    "\n",
    "# Métriques sur l'échantillon de validation\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "auc = roc_auc_score(y_test,y_pred)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "print(\"Best estimator : \"+str(model.best_params_))\n",
    "print(cm)\n",
    "print(\"F1-score : {0:.3f}\".format(f1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamètres \n",
    "params_knn_small={'n_neighbors':[5,9,13,25]} \n",
    "params_knn_large = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec oversampling SMOTE 30/70 + undersampling aléatoire 1:1 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 965086\n",
      "Test set size : 264143\n",
      "[[261923   1365]\n",
      " [   854      1]]\n",
      "F1-score : 0.001\n",
      "ROC AUC score : 0.498\n",
      "Elapsed time : 513.323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "cv = [(slice(None), slice(None))]\n",
    "start = time()\n",
    "#model = GridSearchCV(model, params_knn_small, cv=cv, n_jobs=-1, scoring=make_scorer(f1_score), verbose=3)\n",
    "model.fit(X_train_s3_scaled,y_train_s3)\n",
    "\n",
    "# Prédiction\n",
    "#y_pred = model.best_estimator_.predict(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "#knn_best_params = model.best_params_\n",
    "\n",
    "# Métriques sur l'échantillon de validation\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "auc = roc_auc_score(y_test,y_pred)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "#print(\"Best estimator : \"+str(model.best_params_))\n",
    "print(cm)\n",
    "print(\"F1-score : {0:.3f}\".format(f1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size : 241588\n",
      "Test set size : 264143\n",
      "[[259476   3812]\n",
      " [   836     19]]\n",
      "F1-score : 0.008\n",
      "ROC AUC score : 0.504\n",
      "Elapsed time : 135.638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from time import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start = time()\n",
    "\n",
    "clf1 = LogisticRegression(C=10, class_weight=None, penalty='l2',random_state=1)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf3 = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_leaf=1,random_state=1)\n",
    "\n",
    "#ensemble_model = VotingClassifier(estimators=[('lr', clf1),('knn', clf2), ('dt', clf3)], voting='hard')\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('knn', clf2),('dt', clf3)], voting='soft', weights=[1,1,2])\n",
    "ensemble_model.fit(X_train_s1_scaled, y_train_s1)\n",
    "\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "done = time() \n",
    "tps = round(done - start,3)\n",
    "\n",
    "# Métriques sur l'échantillon de validation\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "auc = roc_auc_score(y_test,y_pred)\n",
    "\n",
    "print(\"Train set size : \"+str(X_train.shape[0]))\n",
    "print(\"Test set size : \"+str(X_test.shape[0]))\n",
    "#print(\"Best estimator : \"+str(lr.best_params_))\n",
    "print(cm)\n",
    "print(\"F1-score : {0:.3f}\".format(f1))\n",
    "print(\"ROC AUC score : {0:.3f}\".format(auc))\n",
    "print(\"Elapsed time : \"+str(tps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
